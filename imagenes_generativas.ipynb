{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c802f3",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2ec7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from hydra import initialize, compose\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfac406",
   "metadata": {},
   "source": [
    "### Se toman las 4 carpetas (cable, capsule, screw y transistor) y se separa su información de testing training y se juntan en un solo dataset, igualmente guardando las etiquetas y se setea el tamaño de cada imagen en 128x128 como se indica en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62d525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "DATASETS = ['cable', 'capsule', 'screw', 'transistor']\n",
    "BASE_PATH = Path('../TareaAutoEncoders')\n",
    "OUTPUT_PATH = BASE_PATH / 'DATASET_128x128'\n",
    "IMAGE_SIZE = (128, 128)\n",
    "\n",
    "# Crear estructura de salida (carpetas planas)\n",
    "for split in ['train', 'test', 'ground_truth']:\n",
    "    (OUTPUT_PATH / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def process_and_save(src_path: Path, dest_dir: Path, prefix: str, is_mask=False):\n",
    "    \"\"\"Lee, redimensiona y guarda. Si is_mask usa INTER_NEAREST.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(src_path), cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ No se pudo leer: {src_path}\")\n",
    "            return False\n",
    "        interp = cv2.INTER_NEAREST if is_mask else cv2.INTER_AREA\n",
    "        resized = cv2.resize(img, IMAGE_SIZE, interpolation=interp)\n",
    "        dest = dest_dir / f\"{prefix}_{src_path.stem}{src_path.suffix}\"\n",
    "        cv2.imwrite(str(dest), resized)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error con {src_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Procesar datasets\n",
    "for dataset in DATASETS:\n",
    "    base = BASE_PATH / dataset\n",
    "\n",
    "    # train -> normalmente sólo 'good' en estos datasets\n",
    "    train_dir = base / 'train'\n",
    "    if train_dir.exists():\n",
    "        for cls in train_dir.iterdir():\n",
    "            if not cls.is_dir(): \n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_train_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'train', prefix, is_mask=False)\n",
    "\n",
    "    # test -> incluir good y defectos\n",
    "    test_dir = base / 'test'\n",
    "    if test_dir.exists():\n",
    "        for cls in test_dir.iterdir():\n",
    "            if not cls.is_dir():\n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_test_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'test', prefix, is_mask=False)\n",
    "\n",
    "    # ground_truth -> máscaras (usar nearest)\n",
    "    gt_dir = base / 'ground_truth'\n",
    "    if gt_dir.exists():\n",
    "        for cls in gt_dir.iterdir():\n",
    "            if not cls.is_dir():\n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_gt_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'ground_truth', prefix, is_mask=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb3c98",
   "metadata": {},
   "source": [
    "## Configuración de los archivos Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123bc177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio conf/ creado\n"
     ]
    }
   ],
   "source": [
    "# Crear estructura base\n",
    "conf_path = Path(\"conf\")\n",
    "conf_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Directorio conf/ creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209cb794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Subdirectorios creados:\n",
      "   - conf/model/\n",
      "   - conf/trainer/\n",
      "   - conf/logger/\n",
      "   - conf/loss/\n",
      "   - conf/optimizer/\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: Crear carpetas necesarias\n",
    "subdirs = [\"model\", \"trainer\", \"logger\", \"loss\", \"optimizer\"]\n",
    "for subdir in subdirs:\n",
    "    (conf_path / subdir).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✅ Subdirectorios creados:\")\n",
    "for subdir in subdirs:\n",
    "    print(f\"   - conf/{subdir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ae3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variaciones de modelo creadas:\n",
      "   - autoencoder_latent_small (128)\n",
      "   - autoencoder_latent_large (1024)\n"
     ]
    }
   ],
   "source": [
    "# Celda: Crear variaciones de configuración para experimentos\n",
    "# Variación 1: Latent dim pequeño\n",
    "latent_small_yaml = \"\"\"name: autoencoder_latent_small\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 128\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_latent_small.yaml\", \"w\") as f:\n",
    "    f.write(latent_small_yaml)\n",
    "\n",
    "# Variación 2: Latent dim grande\n",
    "latent_large_yaml = \"\"\"name: autoencoder_latent_large\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 1024\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_latent_large.yaml\", \"w\") as f:\n",
    "    f.write(latent_large_yaml)\n",
    "\n",
    "print(\"Variaciones de modelo creadas:\")\n",
    "print(\"   - autoencoder_latent_small (128)\")\n",
    "print(\"   - autoencoder_latent_large (1024)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53282c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/config.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 3: Crear conf/config.yaml (configuración principal)\n",
    "config_yaml = \"\"\"defaults:\n",
    "  - model: autoencoder\n",
    "  - trainer: default\n",
    "  - logger: wandb\n",
    "  - loss: l2\n",
    "  - optimizer: adam_mid\n",
    "\n",
    "seed: 42\n",
    "\n",
    "data:\n",
    "  data_dir: 'DATASET_128x128'\n",
    "  image_size: 128\n",
    "  batch_size: 32\n",
    "  num_workers: 0\n",
    "  validation_split: 0.15\n",
    "  test_split: 0.15\n",
    "\n",
    "callbacks:\n",
    "  monitor: \"val/loss\"\n",
    "  mode: \"min\"\n",
    "  filename: \"{epoch:02d}-{val/loss:.4f}\"\n",
    "  save_top_k: 3\n",
    "\n",
    "experiment:\n",
    "  name: \"default_experiment\"\n",
    "  description: \"Default autoencoder experiment\"\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/config.yaml\", \"w\") as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(\"conf/config.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e13d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 4: Crear modelos - conf/model/autoencoder.yaml\n",
    "autoencoder_yaml = \"\"\"name: autoencoder\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 512\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5d4d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/unet.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: Crear modelos - conf/model/unet.yaml\n",
    "unet_yaml = \"\"\"name: unet\n",
    "in_channels: 3\n",
    "base_channels: 32\n",
    "depth: 4\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/unet.yaml\", \"w\") as f:\n",
    "    f.write(unet_yaml)\n",
    "\n",
    "print(\"conf/model/unet.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4fef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder_small.yaml creado (latent_dim: 128)\n"
     ]
    }
   ],
   "source": [
    "# Celda 6: Variaciones de autoencoder con latent_dim pequeño\n",
    "autoencoder_small_yaml = \"\"\"name: autoencoder_small\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128]\n",
    "latent_dim: 128\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_small.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_small_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder_small.yaml creado (latent_dim: 128)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03c99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder_large.yaml creado (latent_dim: 1024)\n"
     ]
    }
   ],
   "source": [
    "# Celda 7: Variaciones de autoencoder con latent_dim grande\n",
    "autoencoder_large_yaml = \"\"\"name: autoencoder_large\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256, 512]\n",
    "latent_dim: 1024\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.1\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_large.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_large_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder_large.yaml creado (latent_dim: 1024)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3cdcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/l1.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 8: Funciones de pérdida - L1\n",
    "l1_yaml = \"\"\"name: l1\n",
    "type: L1Loss\n",
    "weight: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/l1.yaml\", \"w\") as f:\n",
    "    f.write(l1_yaml)\n",
    "\n",
    "print(\"conf/loss/l1.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae19c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/l2.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 9: Funciones de pérdida - L2 (MSE)\n",
    "l2_yaml = \"\"\"name: l2\n",
    "type: MSELoss\n",
    "weight: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/l2.yaml\", \"w\") as f:\n",
    "    f.write(l2_yaml)\n",
    "\n",
    "print(\"conf/loss/l2.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818cd767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/ssim.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 10: Funciones de pérdida - SSIM\n",
    "ssim_yaml = \"\"\"name: ssim\n",
    "type: SSIMLoss\n",
    "weight: 1.0\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/ssim.yaml\", \"w\") as f:\n",
    "    f.write(ssim_yaml)\n",
    "\n",
    "print(\"conf/loss/ssim.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e24c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/ssim_l1.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 11: Funciones de pérdida - SSIM + L1\n",
    "ssim_l1_yaml = \"\"\"name: ssim_l1\n",
    "type: SSIMLoss_L1\n",
    "weight_ssim: 0.5\n",
    "weight_l1: 0.5\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/ssim_l1.yaml\", \"w\") as f:\n",
    "    f.write(ssim_l1_yaml)\n",
    "\n",
    "print(\"conf/loss/ssim_l1.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f27b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/trainer/default.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 12: Trainer - conf/trainer/default.yaml\n",
    "trainer_yaml = \"\"\"max_epochs: 20\n",
    "gpus: 1\n",
    "precision: 32\n",
    "deterministic: true\n",
    "check_val_every_n_epoch: 1\n",
    "log_every_n_steps: 10\n",
    "enable_model_summary: true\n",
    "gradient_clip_val: 0.0\n",
    "enable_progress_bar: true\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/trainer/default.yaml\", \"w\") as f:\n",
    "    f.write(trainer_yaml)\n",
    "\n",
    "print(\"conf/trainer/default.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ea0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/logger/wandb.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 13: Logger - conf/logger/wandb.yaml\n",
    "wandb_yaml = \"\"\"project: ae_experiments\n",
    "entity: null\n",
    "log_model: false\n",
    "offline: false\n",
    "tags: []\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/logger/wandb.yaml\", \"w\") as f:\n",
    "    f.write(wandb_yaml)\n",
    "\n",
    "print(\"conf/logger/wandb.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01369ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_low.yaml creado (lr: 1e-4)\n"
     ]
    }
   ],
   "source": [
    "# Celda 14: Optimizer - Adam con LR bajo\n",
    "adam_low_yaml = \"\"\"name: adam_low\n",
    "type: Adam\n",
    "lr: 1e-4\n",
    "weight_decay: 0.0\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_low.yaml\", \"w\") as f:\n",
    "    f.write(adam_low_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_low.yaml creado (lr: 1e-4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eafba72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_mid.yaml creado (lr: 1e-3)\n"
     ]
    }
   ],
   "source": [
    "# Celda 15: Optimizer - Adam con LR medio\n",
    "adam_mid_yaml = \"\"\"name: adam_mid\n",
    "type: Adam\n",
    "lr: 1e-3\n",
    "weight_decay: 0.0\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_mid.yaml\", \"w\") as f:\n",
    "    f.write(adam_mid_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_mid.yaml creado (lr: 1e-3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f83b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_high.yaml creado (lr: 5e-3)\n"
     ]
    }
   ],
   "source": [
    "# Celda 16: Optimizer - Adam con LR alto\n",
    "adam_high_yaml = \"\"\"name: adam_high\n",
    "type: Adam\n",
    "lr: 5e-3\n",
    "weight_decay: 1e-5\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_high.yaml\", \"w\") as f:\n",
    "    f.write(adam_high_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_high.yaml creado (lr: 5e-3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8291b",
   "metadata": {},
   "source": [
    "## Definición del DataModule y modelo base (Autoencoder clásico con Hydra + PyTorch Lightning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff540c",
   "metadata": {},
   "source": [
    "### Definición del Dataset para DATASET_128x128\n",
    "\n",
    "En esta sección definimos una clase `MVTecDataset` basada en `torch.utils.data.Dataset`\n",
    "que carga las imágenes ya preprocesadas a tamaño **128×128**.\n",
    "\n",
    "Las imágenes se cargan en formato RGB y se convierten a tensores normalizados en \\[0, 1].\n",
    "Este dataset se utilizará dentro del `LightningDataModule` para separar train/val/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3402efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, split=\"train\", transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        split_dir = self.root_dir / split\n",
    "        exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        self.image_paths = [\n",
    "            p for p in split_dir.glob(\"*.*\") if p.suffix.lower() in exts\n",
    "        ]\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(f\"[WARNING] No se encontraron imágenes en {split_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Para autoencoder solo necesitamos la imagen (entrada = salida)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235779d1",
   "metadata": {},
   "source": [
    "### LightningDataModule para MVTec\n",
    "\n",
    "Para estructurar el flujo de datos usando PyTorch Lightning, se define un\n",
    "`LightningDataModule` llamado `MVTecDataModule`.\n",
    "\n",
    "Este módulo:\n",
    "\n",
    "- Recibe los hiperparámetros desde la configuración (`cfg.data`):\n",
    "  - `data_dir`, `batch_size`, `num_workers`, `validation_split`.\n",
    "- Construye el `Dataset` de entrenamiento completo y lo separa en:\n",
    "  - subconjunto de **train**\n",
    "  - subconjunto de **validation** (usando `validation_split`).\n",
    "- Crea el `Dataset` de **test**.\n",
    "- Expone los `DataLoader`:\n",
    "  - `train_dataloader()`\n",
    "  - `val_dataloader()`\n",
    "  - `test_dataloader()`\n",
    "\n",
    "De esta forma, el mismo `DataModule` se reutiliza para todos los modelos y\n",
    "experimentos (distintas funciones de pérdida, arquitecturas, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a39e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        batch_size=32,\n",
    "        num_workers=2,\n",
    "        val_split=0.15,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "\n",
    "        # Transformación básica: convertir a tensor en [0,1]\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Dataset completo de entrenamiento (después se divide en train/val)\n",
    "        full_train = MVTecDataset(\n",
    "            root_dir=self.data_dir,\n",
    "            split=\"train\",\n",
    "            transform=self.transform,\n",
    "        )\n",
    "\n",
    "        n_total = len(full_train)\n",
    "        n_val = int(self.val_split * n_total)\n",
    "        n_train = n_total - n_val\n",
    "\n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(\n",
    "            full_train,\n",
    "            [n_train, n_val],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "\n",
    "        # Dataset de test\n",
    "        self.test_set = MVTecDataset(\n",
    "            root_dir=self.data_dir,\n",
    "            split=\"test\",\n",
    "            transform=self.transform,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_set,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_set,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdfeab",
   "metadata": {},
   "source": [
    "### Construcción de función de pérdida y optimizador desde Hydra\n",
    "\n",
    "La configuración de la tarea se maneja con Hydra. En particular:\n",
    "\n",
    "- `conf/loss/*.yaml` define el tipo de función de pérdida a usar\n",
    "  (L1, L2, SSIM, SSIM + L1, etc.).\n",
    "- `conf/optimizer/*.yaml` define el tipo de optimizador y sus hiperparámetros\n",
    "  (por ejemplo, Adam con distintas tasas de aprendizaje).\n",
    "\n",
    "Para desacoplar el modelo de estas decisiones, se implementan dos funciones:\n",
    "\n",
    "- `build_loss(loss_cfg)`: a partir de `cfg.loss` devuelve un objeto de pérdida\n",
    "  de PyTorch.\n",
    "- `build_optimizer(optimizer_cfg, parameters)`: a partir de `cfg.optimizer`\n",
    "  devuelve una instancia del optimizador apropiado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a64429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(loss_cfg):\n",
    "    \"\"\"\n",
    "    Construye la función de pérdida a partir de cfg.loss.\n",
    "    Por ahora se implementan L1 y L2 (MSE).\n",
    "    \"\"\"\n",
    "    loss_type = loss_cfg.type\n",
    "\n",
    "    if loss_type == \"L1Loss\":\n",
    "        return nn.L1Loss()\n",
    "    elif loss_type == \"MSELoss\":\n",
    "        return nn.MSELoss()\n",
    "    else:\n",
    "        # Aquí luego se agregarán SSIM y SSIM+L1\n",
    "        raise NotImplementedError(f\"Pérdida '{loss_type}' aún no implementada en este notebook.\")\n",
    "    \n",
    "\n",
    "def build_optimizer(optimizer_cfg, parameters):\n",
    "    \"\"\"\n",
    "    Construye el optimizador a partir de cfg.optimizer.\n",
    "    Actualmente soporta Adam con lr configurable.\n",
    "    \"\"\"\n",
    "    opt_type = optimizer_cfg.type\n",
    "\n",
    "    if opt_type == \"Adam\":\n",
    "        return torch.optim.Adam(\n",
    "            parameters,\n",
    "            lr=optimizer_cfg.lr,\n",
    "            weight_decay=optimizer_cfg.weight_decay,\n",
    "            betas=tuple(optimizer_cfg.betas),\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Optimizer '{opt_type}' no implementado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84d0f0",
   "metadata": {},
   "source": [
    "### Modelo base: Autoencoder clásico con PyTorch Lightning\n",
    "\n",
    "En esta sección se define el modelo de **autoencoder clásico** como un\n",
    "`LightningModule` llamado `LitAutoencoder`.\n",
    "\n",
    "Este módulo:\n",
    "\n",
    "- Lee su configuración desde `cfg.model`:\n",
    "  - `in_channels`\n",
    "  - `hidden_dims` (lista de canales intermedios)\n",
    "  - `latent_dim`\n",
    "- Construye un **encoder** convolucional que reduce la resolución de la imagen.\n",
    "- Aplica capas totalmente conectadas para:\n",
    "  - Proyectar la salida del encoder a un espacio latente de dimensión `latent_dim`.\n",
    "  - Reconstruir desde el espacio latente a la forma intermedia del decoder.\n",
    "- Construye un **decoder** con convoluciones transpuestas para recuperar\n",
    "  una imagen de tamaño 128×128 y 3 canales.\n",
    "- Utiliza la función de pérdida definida en `cfg.loss`.\n",
    "- Utiliza el optimizador definido en `cfg.optimizer`.\n",
    "\n",
    "Este modelo será el primero en usarse para los experimentos de la tarea\n",
    "(con distintas funciones de pérdida). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805bbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, model_cfg, loss_cfg, optimizer_cfg, image_size=128):\n",
    "        super().__init__()\n",
    "        # Guardamos la config de modelo como hyperparams (para reproducibilidad)\n",
    "        self.save_hyperparameters(OmegaConf.to_container(model_cfg, resolve=True))\n",
    "\n",
    "        self.model_cfg = model_cfg\n",
    "        self.loss_cfg = loss_cfg\n",
    "        self.optimizer_cfg = optimizer_cfg\n",
    "        self.image_size = image_size\n",
    "\n",
    "        in_channels = model_cfg.in_channels\n",
    "        hidden_dims = list(model_cfg.hidden_dims)\n",
    "        latent_dim = model_cfg.latent_dim\n",
    "\n",
    "        # Encoder: secuencia de convoluciones con stride 2\n",
    "        modules = []\n",
    "        channels = in_channels\n",
    "        size = image_size\n",
    "        for h in hidden_dims:\n",
    "            modules.append(nn.Conv2d(channels, h, kernel_size=3, stride=2, padding=1))\n",
    "            modules.append(nn.ReLU())\n",
    "            channels = h\n",
    "            size = size // 2  # cada conv con stride 2 reduce la mitad\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.enc_out_channels = channels\n",
    "        self.enc_out_size = size\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(channels * size * size, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, channels * size * size)\n",
    "\n",
    "        # Decoder: conv transpuestas para volver a 3x128x128\n",
    "        modules = []\n",
    "        hidden_dims_rev = list(hidden_dims[::-1])\n",
    "\n",
    "        for i in range(len(hidden_dims_rev) - 1):\n",
    "            modules.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    hidden_dims_rev[i],\n",
    "                    hidden_dims_rev[i + 1],\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                )\n",
    "            )\n",
    "            modules.append(nn.ReLU())\n",
    "\n",
    "        modules.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                hidden_dims_rev[-1],\n",
    "                in_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            )\n",
    "        )\n",
    "        modules.append(nn.Sigmoid())  # salida en [0,1]\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        # Pérdida\n",
    "        self.criterion = build_loss(loss_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        x_flat = self.flatten(x_enc)\n",
    "        z = self.fc_mu(x_flat)\n",
    "        x_dec_flat = self.fc_decode(z)\n",
    "        x_dec = x_dec_flat.view(\n",
    "            x.shape[0],\n",
    "            self.enc_out_channels,\n",
    "            self.enc_out_size,\n",
    "            self.enc_out_size,\n",
    "        )\n",
    "        x_hat = self.decoder(x_dec)\n",
    "        return x_hat\n",
    "\n",
    "    def _shared_step(self, batch, stage):\n",
    "        x = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, x)\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = build_optimizer(self.optimizer_cfg, self.parameters())\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a8978",
   "metadata": {},
   "source": [
    "### Función principal de entrenamiento con Hydra y WandB\n",
    "\n",
    "Finalmente, se define una función `train_autoencoder_with_hydra()` que\n",
    "integra todos los componentes anteriores:\n",
    "\n",
    "1. Inicializa Hydra y carga la configuración desde `conf/config.yaml`.\n",
    "2. Construye el `MVTecDataModule` usando `cfg.data`.\n",
    "3. Construye el `LitAutoencoder` usando:\n",
    "   - `cfg.model` (arquitectura del autoencoder clásico),\n",
    "   - `cfg.loss` (función de pérdida),\n",
    "   - `cfg.optimizer` (optimizador).\n",
    "4. Inicializa un `WandbLogger` con los parámetros de `cfg.logger`.\n",
    "5. Crea un `Trainer` de PyTorch Lightning con los parámetros definidos en `cfg.trainer`.\n",
    "6. Llama a `trainer.fit(model, datamodule=dm)` para entrenar el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1d2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_with_hydra():\n",
    "    \"\"\"\n",
    "    Función de entrenamiento principal.\n",
    "    Usa Hydra para cargar conf/config.yaml y los subarchivos.\n",
    "    \"\"\"\n",
    "    with initialize(config_path=\"conf\", version_base=None):\n",
    "        cfg = compose(config_name=\"config\")\n",
    "\n",
    "    print(\"Configuración cargada:\")\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    # DataModule\n",
    "    dm = MVTecDataModule(\n",
    "        data_dir=cfg.data.data_dir,\n",
    "        batch_size=cfg.data.batch_size,\n",
    "        num_workers=cfg.data.num_workers,\n",
    "        val_split=cfg.data.validation_split,\n",
    "    )\n",
    "\n",
    "    # Modelo (autoencoder clásico)\n",
    "    model = LitAutoencoder(\n",
    "        model_cfg=cfg.model,\n",
    "        loss_cfg=cfg.loss,\n",
    "        optimizer_cfg=cfg.optimizer,\n",
    "        image_size=cfg.data.image_size,\n",
    "    )\n",
    "\n",
    "    # Logger de WandB\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=cfg.logger.project,\n",
    "        entity=cfg.logger.entity,\n",
    "        log_model=cfg.logger.log_model,\n",
    "    )\n",
    "\n",
    "    # Trainer a partir de cfg.trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg.trainer.max_epochs,\n",
    "        log_every_n_steps=cfg.trainer.log_every_n_steps,\n",
    "        deterministic=cfg.trainer.deterministic,\n",
    "        enable_model_summary=cfg.trainer.enable_model_summary,\n",
    "        enable_progress_bar=cfg.trainer.enable_progress_bar,\n",
    "        logger=wandb_logger,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c11f34",
   "metadata": {},
   "source": [
    "### Configuraciones de funciones de pérdida (Hydra)\n",
    "\n",
    "Se requiere evaluar distintas funciones de pérdida para el autoencoder:\n",
    "\n",
    "- **L1**  \n",
    "- **L2 (MSE)**  \n",
    "- **SSIM**  \n",
    "- **SSIM + L1**\n",
    "\n",
    "Para permitir cambiar entre estas variantes desde Hydra sin modificar código,\n",
    "se definen cuatro archivos de configuración en `conf/loss/`:\n",
    "\n",
    "- `l1.yaml`\n",
    "- `l2.yaml`\n",
    "- `ssim.yaml`\n",
    "- `ssim_l1.yaml`\n",
    "\n",
    "Cada uno especifica el tipo de pérdida a usar (`type`) y, en el caso de SSIM,\n",
    "algunos hiperparámetros adicionales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8083a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos de configuración de pérdidas creados/actualizados en conf/loss/\n"
     ]
    }
   ],
   "source": [
    "Path(\"conf/loss\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "l1_yaml = \"\"\"type: L1Loss\n",
    "name: \"L1\"\n",
    "\"\"\"\n",
    "\n",
    "l2_yaml = \"\"\"type: MSELoss\n",
    "name: \"L2\"\n",
    "\"\"\"\n",
    "\n",
    "ssim_yaml = \"\"\"type: SSIM\n",
    "name: \"SSIM\"\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "\"\"\"\n",
    "\n",
    "ssim_l1_yaml = \"\"\"type: SSIM_L1\n",
    "name: \"SSIM+L1\"\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "l1_weight: 0.1\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/l1.yaml\", \"w\") as f:\n",
    "    f.write(l1_yaml)\n",
    "\n",
    "with open(\"conf/loss/l2.yaml\", \"w\") as f:\n",
    "    f.write(l2_yaml)\n",
    "\n",
    "with open(\"conf/loss/ssim.yaml\", \"w\") as f:\n",
    "    f.write(ssim_yaml)\n",
    "\n",
    "with open(\"conf/loss/ssim_l1.yaml\", \"w\") as f:\n",
    "    f.write(ssim_l1_yaml)\n",
    "\n",
    "print(\"Archivos de configuración de pérdidas creados/actualizados en conf/loss/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70f880",
   "metadata": {},
   "source": [
    "### Implementación de la pérdida SSIM\n",
    "\n",
    "La métrica **Structural Similarity Index (SSIM)** mide la similitud estructural\n",
    "entre dos imágenes. A diferencia de L1/L2, que comparan píxel a píxel,\n",
    "SSIM toma en cuenta:\n",
    "\n",
    "- luminancia,\n",
    "- contraste,\n",
    "- estructura local.\n",
    "\n",
    "Para usar SSIM como pérdida, se suele minimizar `1 - SSIM(x, y)`, donde `x` es\n",
    "la imagen original y `y` la reconstrucción del autoencoder.\n",
    "\n",
    "A continuación se define una implementación en PyTorch que:\n",
    "\n",
    "- Convierte la fórmula de SSIM a operaciones de convolución 2D con un kernel\n",
    "  gaussiano.\n",
    "- Calcula SSIM de forma local y luego promedia el resultado.\n",
    "- Devuelve `1 - SSIM` como valor de pérdida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e81108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size=11,\n",
    "        sigma=1.5,\n",
    "        data_range=1.0,\n",
    "        channel=3,\n",
    "        K1=0.01,\n",
    "        K2=0.03,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementación de SSIM como pérdida: loss = 1 - SSIM.\n",
    "        Asume imágenes en rango [0, data_range] y 3 canales por defecto.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.sigma = sigma\n",
    "        self.data_range = data_range\n",
    "        self.channel = channel\n",
    "        self.K1 = K1\n",
    "        self.K2 = K2\n",
    "\n",
    "        self.register_buffer(\"window\", self._create_window(window_size, sigma, channel))\n",
    "\n",
    "    def _gaussian(self, window_size, sigma):\n",
    "        gauss = torch.tensor(\n",
    "            [\n",
    "                (-(x - window_size // 2) ** 2) / float(2 * sigma**2)\n",
    "                for x in range(window_size)\n",
    "            ]\n",
    "        )\n",
    "        gauss = torch.exp(gauss)\n",
    "        return gauss / gauss.sum()\n",
    "\n",
    "    def _create_window(self, window_size, sigma, channel):\n",
    "        _1d_window = self._gaussian(window_size, sigma).unsqueeze(1)\n",
    "        _2d_window = _1d_window @ _1d_window.t()  # producto externo\n",
    "        _2d_window = _2d_window.float().unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\n",
    "        window = _2d_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "        return window\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        x, y: tensores [B, C, H, W] en rango [0, data_range]\n",
    "        Devuelve 1 - SSIM promedio en el batch.\n",
    "        \"\"\"\n",
    "        if x.size(1) != self.channel or y.size(1) != self.channel:\n",
    "            # Simplemente adaptamos el canal si es distinto (por si acaso)\n",
    "            self.channel = x.size(1)\n",
    "            self.window = self._create_window(self.window_size, self.sigma, self.channel).to(x.device)\n",
    "\n",
    "        # Constantes de SSIM\n",
    "        C1 = (self.K1 * self.data_range) ** 2\n",
    "        C2 = (self.K2 * self.data_range) ** 2\n",
    "\n",
    "        # Media local\n",
    "        mu_x = torch.nn.functional.conv2d(\n",
    "            x, self.window, padding=self.window_size // 2, groups=self.channel\n",
    "        )\n",
    "        mu_y = torch.nn.functional.conv2d(\n",
    "            y, self.window, padding=self.window_size // 2, groups=self.channel\n",
    "        )\n",
    "\n",
    "        mu_x2 = mu_x * mu_x\n",
    "        mu_y2 = mu_y * mu_y\n",
    "        mu_xy = mu_x * mu_y\n",
    "\n",
    "        # Varianzas y covarianza\n",
    "        sigma_x2 = torch.nn.functional.conv2d(\n",
    "            x * x, self.window, padding=self.window_size // 2, groups=self.channel\n",
    "        ) - mu_x2\n",
    "        sigma_y2 = torch.nn.functional.conv2d(\n",
    "            y * y, self.window, padding=self.window_size // 2, groups=self.channel\n",
    "        ) - mu_y2\n",
    "        sigma_xy = torch.nn.functional.conv2d(\n",
    "            x * y, self.window, padding=self.window_size // 2, groups=self.channel\n",
    "        ) - mu_xy\n",
    "\n",
    "        # Fórmula de SSIM\n",
    "        num = (2 * mu_xy + C1) * (2 * sigma_xy + C2)\n",
    "        den = (mu_x2 + mu_y2 + C1) * (sigma_x2 + sigma_y2 + C2)\n",
    "\n",
    "        ssim_map = num / (den + 1e-8)\n",
    "        ssim = ssim_map.mean()\n",
    "\n",
    "        # Pérdida = 1 - SSIM promedio\n",
    "        loss = 1 - ssim\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e06b0a",
   "metadata": {},
   "source": [
    "### Actualización de `build_loss` para incluir SSIM y SSIM+L1\n",
    "\n",
    "Con la clase `SSIMLoss` definida, se extiende la función `build_loss` para\n",
    "reconocer cuatro tipos de pérdida:\n",
    "\n",
    "- `L1Loss`  → L1 estándar.\n",
    "- `MSELoss` → L2 (MSE).\n",
    "- `SSIM`    → `1 - SSIM(x, y)`.\n",
    "- `SSIM_L1` → combinación lineal de SSIM y L1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259180f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(loss_cfg):\n",
    "    \"\"\"\n",
    "    Construye la función de pérdida a partir de cfg.loss.\n",
    "\n",
    "    Soporta:\n",
    "      - L1Loss\n",
    "      - MSELoss\n",
    "      - SSIM\n",
    "      - SSIM_L1 (combinación SSIM + L1)\n",
    "    \"\"\"\n",
    "    loss_type = loss_cfg.type\n",
    "\n",
    "    if loss_type == \"L1Loss\":\n",
    "        return nn.L1Loss()\n",
    "\n",
    "    elif loss_type == \"MSELoss\":\n",
    "        return nn.MSELoss()\n",
    "\n",
    "    elif loss_type == \"SSIM\":\n",
    "        return SSIMLoss(\n",
    "            window_size=loss_cfg.window_size,\n",
    "            sigma=loss_cfg.sigma,\n",
    "            data_range=loss_cfg.data_range,\n",
    "            channel=3,  # nuestras imágenes son RGB\n",
    "        )\n",
    "\n",
    "    elif loss_type == \"SSIM_L1\":\n",
    "        ssim_loss = SSIMLoss(\n",
    "            window_size=loss_cfg.window_size,\n",
    "            sigma=loss_cfg.sigma,\n",
    "            data_range=loss_cfg.data_range,\n",
    "            channel=3,\n",
    "        )\n",
    "        l1 = nn.L1Loss()\n",
    "        l1_weight = loss_cfg.l1_weight\n",
    "\n",
    "        class SSIML1Combined(nn.Module):\n",
    "            def __init__(self, ssim_loss, l1, l1_weight):\n",
    "                super().__init__()\n",
    "                self.ssim_loss = ssim_loss\n",
    "                self.l1 = l1\n",
    "                self.l1_weight = l1_weight\n",
    "\n",
    "            def forward(self, x, y):\n",
    "                loss_ssim = self.ssim_loss(x, y)        # 1 - SSIM\n",
    "                loss_l1 = self.l1(x, y)\n",
    "                return loss_ssim + self.l1_weight * loss_l1\n",
    "\n",
    "        return SSIML1Combined(ssim_loss, l1, l1_weight)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Pérdida '{loss_type}' aún no implementada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d536a7d",
   "metadata": {},
   "source": [
    "### Configuración del modelo U-Net (Hydra)\n",
    "\n",
    "Se requiere evaluar un autoencoder clásico y un autoencoder tipo **U-Net**.\n",
    "\n",
    "Para permitir seleccionar esta arquitectura desde Hydra sin modificar el código,\n",
    "se crea el archivo `conf/model/unet.yaml`, donde se definen sus parámetros:\n",
    "\n",
    "- `in_channels`: número de canales de entrada (3 para RGB)\n",
    "- `base_channels`: número inicial de filtros del encoder\n",
    "- `depth`: cantidad de niveles de downsampling / upsampling\n",
    "- `latent_dim`: tamaño del cuello (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99ca031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/unet.yaml creado\n"
     ]
    }
   ],
   "source": [
    "Path(\"conf/model\").mkdir(exist_ok=True)\n",
    "\n",
    "unet_yaml = \"\"\"in_channels: 3\n",
    "base_channels: 32\n",
    "depth: 4\n",
    "latent_dim: 128\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/unet.yaml\", \"w\") as f:\n",
    "    f.write(unet_yaml)\n",
    "\n",
    "print(\"conf/model/unet.yaml creado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd082bc",
   "metadata": {},
   "source": [
    "### Implementación del Autoencoder U-Net\n",
    "\n",
    "Este modelo sigue una estructura típica de U-Net:\n",
    "\n",
    "1. **Encoder**:\n",
    "   - Múltiples niveles de convoluciones + downsampling (stride 2).\n",
    "   - Se almacenan características para las conexiones tipo \"skip\".\n",
    "\n",
    "2. **Bottleneck**:\n",
    "   - Capa completamente conectada para pasar al espacio latente.\n",
    "\n",
    "3. **Decoder**:\n",
    "   - ConvTransposed2D para upsampling simétrico.\n",
    "   - Se concatenan los \"skip connections\" del encoder.\n",
    "\n",
    "Este modelo debe:\n",
    "- Usar la misma función de pérdida configurada en `cfg.loss`\n",
    "- Usar el mismo optimizador configurado en `cfg.optimizer`\n",
    "- Ser llamado desde Hydra con:\n",
    "  `defaults: - model: unet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f64b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetEncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNetDecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(out_ch * 2, out_ch, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class LitUNetAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, model_cfg, loss_cfg, optimizer_cfg):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(OmegaConf.to_container(model_cfg, resolve=True))\n",
    "\n",
    "        self.model_cfg = model_cfg\n",
    "        self.loss_cfg = loss_cfg\n",
    "        self.optimizer_cfg = optimizer_cfg\n",
    "\n",
    "        base = model_cfg.base_channels\n",
    "        depth = model_cfg.depth\n",
    "        in_ch = model_cfg.in_channels\n",
    "\n",
    "        # ----- Encoder -----\n",
    "        self.enc_blocks = nn.ModuleList()\n",
    "        self.downsamples = nn.ModuleList()\n",
    "        ch = in_ch\n",
    "        channels = []\n",
    "\n",
    "        for d in range(depth):\n",
    "            out_ch = base * (2 ** d)\n",
    "            self.enc_blocks.append(UNetEncoderBlock(ch, out_ch))\n",
    "            channels.append(out_ch)\n",
    "            ch = out_ch\n",
    "            self.downsamples.append(nn.Conv2d(out_ch, out_ch, kernel_size=2, stride=2))\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = UNetEncoderBlock(ch, ch * 2)\n",
    "\n",
    "        # ----- Decoder -----\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "        ch = ch * 2\n",
    "\n",
    "        for d in reversed(range(depth)):\n",
    "            out_ch = base * (2 ** d)\n",
    "            self.up_blocks.append(nn.ConvTranspose2d(ch, out_ch, kernel_size=2, stride=2))\n",
    "            self.dec_blocks.append(UNetDecoderBlock(out_ch, out_ch))\n",
    "            ch = out_ch\n",
    "\n",
    "        # Output (3 canales)\n",
    "        self.final_conv = nn.Conv2d(base, 3, kernel_size=1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = build_loss(loss_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        out = x\n",
    "\n",
    "        # Encoder\n",
    "        for enc, down in zip(self.enc_blocks, self.downsamples):\n",
    "            out = enc(out)\n",
    "            skips.append(out)\n",
    "            out = down(out)\n",
    "\n",
    "        # Bottleneck\n",
    "        out = self.bottleneck(out)\n",
    "\n",
    "        # Decoder\n",
    "        for up, dec, skip in zip(self.up_blocks, self.dec_blocks, reversed(skips)):\n",
    "            out = up(out)\n",
    "            out = torch.cat([out, skip], dim=1)\n",
    "            out = dec(out, skip)\n",
    "\n",
    "        out = self.final_conv(out)\n",
    "        return self.activation(out)\n",
    "\n",
    "    def _shared_step(self, batch, stage):\n",
    "        x = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, x)\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return build_optimizer(self.optimizer_cfg, self.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2f92b",
   "metadata": {},
   "source": [
    "### Función de entrenamiento para soportar Autoencoder y U-Net\n",
    "\n",
    "Se reescribe la función `train_autoencoder_with_hydra()` para:\n",
    "\n",
    "- Cargar la configuración completa desde Hydra.\n",
    "- Crear automáticamente el DataModule.\n",
    "- Instanciar el modelo según `cfg.model`:\n",
    "  - `autoencoder` → `LitAutoencoder`\n",
    "  - `unet` → `LitUNetAutoencoder`\n",
    "- Inicializar WandB.\n",
    "- Crear un Trainer de Lightning.\n",
    "- Entrenar el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eeb15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_with_hydra():\n",
    "    \"\"\"\n",
    "    Versión actualizada: soporta modelos 'autoencoder' y 'unet'.\n",
    "    Utiliza Hydra + Lightning + WandB para ejecutar entrenamientos reproducibles.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Cargar configuración completa desde Hydra\n",
    "    with initialize(config_path=\"conf\", version_base=None):\n",
    "        cfg = compose(config_name=\"config\")\n",
    "\n",
    "    print(\"=========== CONFIGURACIÓN CARGADA ===========\")\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    # 2. Crear DataModule con los parámetros de cfg.data\n",
    "    dm = MVTecDataModule(\n",
    "        data_dir=cfg.data.data_dir,\n",
    "        batch_size=cfg.data.batch_size,\n",
    "        num_workers=cfg.data.num_workers,\n",
    "        val_split=cfg.data.validation_split,\n",
    "    )\n",
    "\n",
    "    # 3. Instanciar modelo según cfg.model\n",
    "    model_type = cfg.model._target_ if \"_target_\" in cfg.model else None\n",
    "\n",
    "    # Detectar cuál modelo estamos usando\n",
    "    if \"unet\" in cfg.model.__dict__['_content'] or \"unet\" in str(cfg.model):\n",
    "        print(\"📌 Instanciando modelo: U-Net Autoencoder\")\n",
    "        model = LitUNetAutoencoder(\n",
    "            model_cfg=cfg.model,\n",
    "            loss_cfg=cfg.loss,\n",
    "            optimizer_cfg=cfg.optimizer,\n",
    "        )\n",
    "    else:\n",
    "        print(\"📌 Instanciando modelo: Autoencoder clásico\")\n",
    "        model = LitAutoencoder(\n",
    "            model_cfg=cfg.model,\n",
    "            loss_cfg=cfg.loss,\n",
    "            optimizer_cfg=cfg.optimizer,\n",
    "            image_size=cfg.data.image_size,\n",
    "        )\n",
    "\n",
    "    # 4. WandB Logger\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=cfg.logger.project,\n",
    "        entity=cfg.logger.entity,\n",
    "        log_model=cfg.logger.log_model,\n",
    "    )\n",
    "\n",
    "    # 5. Trainer de Lightning con parámetros de Hydra\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg.trainer.max_epochs,\n",
    "        log_every_n_steps=cfg.trainer.log_every_n_steps,\n",
    "        deterministic=cfg.trainer.deterministic,\n",
    "        enable_model_summary=cfg.trainer.enable_model_summary,\n",
    "        enable_progress_bar=cfg.trainer.enable_progress_bar,\n",
    "        logger=wandb_logger,\n",
    "    )\n",
    "\n",
    "    # 6. Entrenamiento\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    print(\"✨ Entrenamiento finalizado correctamente ✨\")\n",
    "\n",
    "    return model, dm, cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a88f9d",
   "metadata": {},
   "source": [
    "## Experimentación con WandB(Weight and Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b40c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INICIANDO EXPERIMENTACIÓN CON 12 CONFIGURACIONES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/12] Ejecutando: ae_small_l1_low\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_134424-dsu1mgwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/dsu1mgwq' target=\"_blank\">ae_small_l1_low</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/dsu1mgwq' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/dsu1mgwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_small_l1_low\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_small\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  latent_dim: 128\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.0\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: L1Loss\n",
      "  name: L1\n",
      "optimizer:\n",
      "  name: adam_low\n",
      "  type: Adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 93.2 K | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 4.2 M  | train\n",
      "3 | fc_decode | Linear     | 4.2 M  | train\n",
      "4 | decoder   | Sequential | 165 K  | train\n",
      "5 | criterion | L1Loss     | 0      | train\n",
      "-------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.721    Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e072aa13bc4926a3614e050ccd6bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431e814de9bc4122832839ac09712e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd577ab475741309e31ed11db49fabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706e89b549c24c8b9749f9293be2fe82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 0.171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d086eebed89f497f83ce95a77b09a4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a2449a51884cf2887478faae30b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487ec1f005464d66ac9de63ed1c8b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a3bea90ef24ba09df9cc6bffd28544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3746d0d4186c41f2a718a11333eb97ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ec610413e54f8cbeb7657bf1b73a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b681fbe9fa94c86a700b98a51c36d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e710e89e114133bc0e86670e3fde04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f35130bcec5496a8d0c3ce13ac6bf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f7c1f1fd3f4d82844e24a3210e82dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e78847023641cd8d633c560dc5e9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c31093c182f47b89b3cbedf31a7b826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aed625921f04aaf8a21879cb0252f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699f99833ff04d02b3b3e3716e642f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d39611d6c794602bf461bb66c3184c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e509ca000641deb3643425e00cd39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e7e5e2885f4172bffe9f9382d4017c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbaf2b2d1324581b324b23cc56202d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.048\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e186e4de7860453f98382e1c49c508da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.05077502131462097\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_small_l1_low\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.05078</td></tr><tr><td>train_loss</td><td>0.04511</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.04799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_small_l1_low</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/dsu1mgwq' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/dsu1mgwq</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_134424-dsu1mgwq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/12] Ejecutando: ae_small_l2_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_134712-jhywrr80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/jhywrr80' target=\"_blank\">ae_small_l2_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/jhywrr80' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/jhywrr80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_small_l2_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_small\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  latent_dim: 128\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.0\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: MSELoss\n",
      "  name: L2\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 93.2 K | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 4.2 M  | train\n",
      "3 | fc_decode | Linear     | 4.2 M  | train\n",
      "4 | decoder   | Sequential | 165 K  | train\n",
      "5 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.721    Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f3b6916abe4d5dba2684de282f994a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62acffa43804951a654f4d2f62837a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271a615e93804f3fa86e83e5d8e6e3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec3e49b9fb34aa2b1a333b79cf4f04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c5d606144648d4841dbc54200983b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f7405994a54e97b94e1d018a82d0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65c68a095fa4fa980082ebde240abf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c42816cf2a41d2ad6867091de51851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4220140b15a146428e1120e49571a4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed41a922b4534db2acd69200e63fc1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f9f286f2dd469bb465a7efbe7031e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcfe2c0ed5043a9ade37a668db5d290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9ba4cb1f84c89874139847edfe449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4318975c37f44e959a72294ae2268ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fa9abfa68c4246bd6952ca2e130084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77995a322e5a4acf9e843d50611b1a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f963aba3edae44d1843a8922429766ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518eef5e24674df583fde778d906a26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315e080069f3481e9b5b9c67ac5eda3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd0781d69514a64a035d827c1776dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe4c29fc8bc4d0f8b21edbbb27258fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327fd3c5d1fc426dac75fc96b5885502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bd109262f345a080fe84ccbebf1dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.003878991585224867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_small_l2_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.00388</td></tr><tr><td>train_loss</td><td>0.00304</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.00298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_small_l2_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/jhywrr80' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/jhywrr80</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_134712-jhywrr80\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/12] Ejecutando: ae_small_ssim_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_134929-35ee09mn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/35ee09mn' target=\"_blank\">ae_small_ssim_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/35ee09mn' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/35ee09mn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_small_ssim_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_small\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  latent_dim: 128\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.0\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM\n",
      "  name: SSIM\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 93.2 K | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 4.2 M  | train\n",
      "3 | fc_decode | Linear     | 4.2 M  | train\n",
      "4 | decoder   | Sequential | 165 K  | train\n",
      "5 | criterion | SSIMLoss   | 0      | train\n",
      "-------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.721    Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2e8059c7444094a796db5458bbb511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82ed52ddd984af7aac458ccf05163f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ec656a2e7f49859559e79506a7e1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fdfe8e3e89461e999329d69d53ebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.153 >= min_delta = 0.0. New best score: 0.300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef01a2e980c245e89b0732388a69ea2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.045 >= min_delta = 0.0. New best score: 0.255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43263d2c0d1945ef8e50212df6279b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffca296e28904756b70d2c1a8a0ca932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da7b162fafa483ba7b49e85745479a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d72f16355c40f68038fc4204643c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fafdb7afe348b89af09cbaf9c4f46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f645cfc0a243598a7d0e211a113574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b074bae2696d40bcb764e3c9146d8898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6b71a05c8c4089932cc6317130bca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8dcf0bc54b4921b42ef1bd54369468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eaba708f40485187479984512fa6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20895793619f4b8ab71f8af9cda160da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e11f3a988d44674915bb4b75550f4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c571fc3ff0a7494cacfeb9c5e957c069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d434952a4b634479877702190c2fdd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bfff32fc3e4002baedfd9e2ef81122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74efbfcf5f3a4500baee144fc1462c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c2df5725ba4740aefcbd7416a75631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.136\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82696a7a21794ae39cad2d11db3ceb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.16018927097320557\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_small_ssim_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▃▄▄▃▄▃▄▂▃▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.16019</td></tr><tr><td>train_loss</td><td>0.11643</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.13586</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_small_ssim_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/35ee09mn' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/35ee09mn</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_134929-35ee09mn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/12] Ejecutando: ae_small_ssim_l1_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_135218-3miaaeel</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/3miaaeel' target=\"_blank\">ae_small_ssim_l1_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/3miaaeel' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/3miaaeel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_small_ssim_l1_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_small\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  latent_dim: 128\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.0\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM_L1\n",
      "  name: SSIM+L1\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "  l1_weight: 0.1\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder   | Sequential     | 93.2 K | train\n",
      "1 | flatten   | Flatten        | 0      | train\n",
      "2 | fc_mu     | Linear         | 4.2 M  | train\n",
      "3 | fc_decode | Linear         | 4.2 M  | train\n",
      "4 | decoder   | Sequential     | 165 K  | train\n",
      "5 | criterion | SSIML1Combined | 0      | train\n",
      "-----------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.721    Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb28f949cd0c4febaee436eb35338252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d29befd9314b158d973404a3a8cc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee567ef626f74474afcde20b516836d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e456d5233c41fbb909922a51f6dc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.180 >= min_delta = 0.0. New best score: 0.312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0963ac05976d4f8fbac0b3a1b21a8e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.048 >= min_delta = 0.0. New best score: 0.264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf90f99912c4256a36cf31e4125ff3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d537f47714249b4ae31b283121fe44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: 0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81896d2a263746e18064fe2a259c6946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28593f48f524c5da6889b003f56e6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb472faa01c4449b9f3c6bac2d68e368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca18035304743d18111f5ee1be69c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ea607bad9644f8924993d2bb962bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b1b84b905d4bd4a15e066e9b1f5c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf54070757342b78bd9c033846342d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a743786d2794e9983d04951d2103112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a48a65613cd4f31988a3f3dc7d94867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eadda128d5a48d1bba28a7b83c914bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c8a6c3afc04448955165649e7b6b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa22991455c48c78e2944ed19ccd853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b81fcf8ced482e8a625b82a7c6cd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c29a7abccc43b5893231c7c687c595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b628fcd0e43b42c5a9505a3843c9c7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.142\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa12f6f8b6ba4af89ef19f4d84847839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.16695445775985718\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_small_ssim_l1_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▇█▆▅▄▄▄▄▄▃▄▃▃▂▃▃▃▃▃▂▂▂▁▂▂▁▂▂▂▁▂▂▂▂▂▂▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.16695</td></tr><tr><td>train_loss</td><td>0.14165</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.14241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_small_ssim_l1_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/3miaaeel' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/3miaaeel</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_135218-3miaaeel\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/12] Ejecutando: ae_large_l1_low\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_135459-b5u72g42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/b5u72g42' target=\"_blank\">ae_large_l1_low</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/b5u72g42' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/b5u72g42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_large_l1_low\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_large\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  latent_dim: 1024\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.1\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: L1Loss\n",
      "  name: L1\n",
      "optimizer:\n",
      "  name: adam_low\n",
      "  type: Adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 1.6 M  | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 8.4 M  | train\n",
      "3 | fc_decode | Linear     | 8.4 M  | train\n",
      "4 | decoder   | Sequential | 2.8 M  | train\n",
      "5 | criterion | L1Loss     | 0      | train\n",
      "-------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.1 M    Total params\n",
      "84.569    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592cdfd8f2a6416fa1cbf90d7dc12da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf236173db94ea4bf40c2eee3e73aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9be42125bcf42848b50753dde3bc67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c0b0b37c084ea986a6b09568cf3376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.045 >= min_delta = 0.0. New best score: 0.197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e1684b836548a0a0d67c3bc7836a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 0.156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b47f3af9d04953b755bd304f2ff847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: 0.136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dd9d87aa9f496dbc28ed6c1bf98d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d369fefdf5ce4313a1d81cdd8889951b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d358eb3c2ec4f45acadf8c1be502754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff0777a16ff4306a8757a6739f443f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e390fe6becf41c1b7f3f803fcb1a652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc27257a41e47beadc7fc88b869f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34505f37029946dc97b57d900bb77246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e166c518d6b472c87ad9993498fbad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d80c8fbaac049bc937c9b257f056859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad178de57cb3472eb838b1e1036275f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170eecdaf0324caeb2f8e95883e0006b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648ea978e21448428b9d208b25f448ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257950188d0f4b9797963d7f6204cece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d35327cc1f4e099605ac59e75c1ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7944335ce1e94827b0422cd7250ffa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2117174b87b4dcf87ee66e08dcae044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.049\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e574028bff4f3a8d94361504c83d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.05258234962821007\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_large_l1_low\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>███▇▆▅▅▄▅▄▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.05258</td></tr><tr><td>train_loss</td><td>0.0574</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.04943</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_large_l1_low</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/b5u72g42' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/b5u72g42</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_135459-b5u72g42\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/12] Ejecutando: ae_large_l2_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_135934-x7euca0d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/x7euca0d' target=\"_blank\">ae_large_l2_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/x7euca0d' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/x7euca0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_large_l2_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_large\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  latent_dim: 1024\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.1\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: MSELoss\n",
      "  name: L2\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 1.6 M  | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 8.4 M  | train\n",
      "3 | fc_decode | Linear     | 8.4 M  | train\n",
      "4 | decoder   | Sequential | 2.8 M  | train\n",
      "5 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.1 M    Total params\n",
      "84.569    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f7a39dfd5a4e28bf431fb0fced7490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675ff3aab51147e1bc5e0c577a7de6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b64f49f879c4498849bfdab712c0575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec824932c994e57a3a98dfe3ccb1529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42b16468de042cab1833a72a89f9d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28eb0a5b4eb4b23a47cea4f1a330ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef03e36afa1d419eb2f9cb6bf5ec7c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944c9e25885347d8828cee3a0dc0b67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87eaaefc09246fd94928c464d5e63b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5977c1571d4d23916a29a1522556f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c576a90d5f834094b719f1126d67d5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ffea26c2664709990126ec5a2df574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff955fd5800b4cfe89d410fd87bd92c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d4ef4a9a234d1cb3f7f9fd6d572707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780b9fc089e441d8958b333e4a8208d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0856cf53ee0e48589a2c704a02497a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff6d49c42cb4934a8e39ac01995fdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36eca2c70984021b07485416f801100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81a6a7d080e45b1a6df195e3469bbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8b05ca54e44e139da983aa6f0842c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc89400347147a68c9a338edff84cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bc9c15b4294840802de7b8f2fc934e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2143fc276c5d4e628f91149d4a13b16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.005748684983700514\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_large_l2_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▅▅▃▃▃▃▃▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.00575</td></tr><tr><td>train_loss</td><td>0.00599</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.00488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_large_l2_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/x7euca0d' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/x7euca0d</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_135934-x7euca0d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/12] Ejecutando: ae_large_ssim_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_140446-sm6aazb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/sm6aazb6' target=\"_blank\">ae_large_ssim_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/sm6aazb6' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/sm6aazb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_large_ssim_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_large\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  latent_dim: 1024\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.1\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM\n",
      "  name: SSIM\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 1.6 M  | train\n",
      "1 | flatten   | Flatten    | 0      | train\n",
      "2 | fc_mu     | Linear     | 8.4 M  | train\n",
      "3 | fc_decode | Linear     | 8.4 M  | train\n",
      "4 | decoder   | Sequential | 2.8 M  | train\n",
      "5 | criterion | SSIMLoss   | 0      | train\n",
      "-------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.1 M    Total params\n",
      "84.569    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c47c83ea880401ab10364afe67419b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2783ab2edba6404db0b1e9dc29715c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa72138e1428442ba79f87873c635420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330ba02fd54e43da95fd07c718228bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.146 >= min_delta = 0.0. New best score: 0.302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178009329b85469ba4284f356f0908bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.050 >= min_delta = 0.0. New best score: 0.253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181fcc68030c470bb2f76203bc2c0528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365b7c94438c43a19983f463679cba2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6b0f4368674c9fbfb882e0fecfc731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb23791a27647cca3ea3107f7209702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0ef23bcbf3479fbac34bdf33e4115c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3af7b9297d42e1993b74a9257179cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5319b6d8fde4a36b648f5e65c14f7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e0b6df5fb0466e997cec6f7a6f203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7752647e33af4f9e8c4238add21076bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f58fc937e548d4b803a4db5a8ae7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8a3b399baa4e9485a168dc40febfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cb4fc829234d4a865676422d5462fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff71deedd8b24510843738be217f3438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45965dcb924e4cfb99d8b0ad53f09906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d676d0df6448b6b2e8dfd88bb036e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b575607831954ba1a3d13d684fc9dbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a5d6e19fd145f9a87b0d60f3915d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.161\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa1c0f42de41feba2f10ac40f794c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.18609608709812164\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_large_ssim_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▇█▆▆▄▃▃▃▃▃▃▃▄▃▃▂▂▂▂▂▂▁▂▂▂▃▂▂▂▁▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.1861</td></tr><tr><td>train_loss</td><td>0.13171</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.16114</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_large_ssim_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/sm6aazb6' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/sm6aazb6</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_140446-sm6aazb6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/12] Ejecutando: ae_large_ssim_l1_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_141034-gnxncuuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/gnxncuuo' target=\"_blank\">ae_large_ssim_l1_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/gnxncuuo' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/gnxncuuo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: ae_large_ssim_l1_mid\n",
      "============================================================\n",
      "model:\n",
      "  name: autoencoder_large\n",
      "  in_channels: 3\n",
      "  hidden_dims:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  latent_dim: 1024\n",
      "  use_batch_norm: true\n",
      "  dropout_rate: 0.1\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM_L1\n",
      "  name: SSIM+L1\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "  l1_weight: 0.1\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: Autoencoder Clásico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder   | Sequential     | 1.6 M  | train\n",
      "1 | flatten   | Flatten        | 0      | train\n",
      "2 | fc_mu     | Linear         | 8.4 M  | train\n",
      "3 | fc_decode | Linear         | 8.4 M  | train\n",
      "4 | decoder   | Sequential     | 2.8 M  | train\n",
      "5 | criterion | SSIML1Combined | 0      | train\n",
      "-----------------------------------------------------\n",
      "21.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.1 M    Total params\n",
      "84.569    Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0880a7fc74e4a45aeff2b30dce10e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2432fb9adbca46be8debfd7df2e4f36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723c37b7e724b91a619bd1d78890605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f3e5ede6014e10bd0e6bd9e06712b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.109 >= min_delta = 0.0. New best score: 0.387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9712c8444243f0a5651a6e26302d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.105 >= min_delta = 0.0. New best score: 0.282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3d8eb0256e4b0da829f73947a58bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 0.254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3e300de2db4c2c9aa64fa20f7bbdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a346d7fecf454acf96eda9b177e874c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae7693b091e4f4ea392d114df8e1936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db09f5ac9ef47529667d39e95df0de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5573e9f8845c436981ce8ded174aeb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca64af3f026d4a19a341f6e9636cb306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131c3d95630d43758efe52d7e50227fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2aa7f2481a740a58d7405117e857e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be2eb8b948e4c2bac6acfc94abf39c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbb1e9bfd134375a4045dab272560ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a152a11448374abcbd5670ed8a8bb52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffecad0333ab4232b557656cbfc5dd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Aplicando PCA a 146 muestras...\n",
      "⚠️ Error en AnomalyDetectionVisualizer: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 1 dimension(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e96bfea1b3e4bb7944867487d3744d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4ee892bb4c4fcb835bc7a00a717623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d2babb32a42c6ba7641eccd3cc22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416360fbda97452481df846a8a5ab336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.167\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando en test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246aec54ee97405c8747f863453e9868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.19104863703250885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✅ Experimento completado: ae_large_ssim_l1_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▇█▇▆▄▄▃▄▃▃▃▃▃▂▂▂▃▃▃▂▁▃▂▃▂▃▂▁▂▃▁▂▁▂▁▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>final_train_loss</td><td>0</td></tr><tr><td>final_val_loss</td><td>0</td></tr><tr><td>test_loss</td><td>0.19105</td></tr><tr><td>train_loss</td><td>0.17715</td></tr><tr><td>trainer/global_step</td><td>520</td></tr><tr><td>val_loss</td><td>0.16679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_large_ssim_l1_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/gnxncuuo' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/gnxncuuo</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 89 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_141034-gnxncuuo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9/12] Ejecutando: unet_l1_low\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_141519-898iyflz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/898iyflz' target=\"_blank\">unet_l1_low</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/898iyflz' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/898iyflz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: unet_l1_low\n",
      "============================================================\n",
      "model:\n",
      "  in_channels: 3\n",
      "  base_channels: 32\n",
      "  depth: 4\n",
      "  latent_dim: 128\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: L1Loss\n",
      "  name: L1\n",
      "optimizer:\n",
      "  name: adam_low\n",
      "  type: Adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: U-Net Autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | enc_blocks  | ModuleList       | 1.2 M  | train\n",
      "1 | downsamples | ModuleList       | 348 K  | train\n",
      "2 | bottleneck  | UNetEncoderBlock | 3.5 M  | train\n",
      "3 | up_blocks   | ModuleList       | 696 K  | train\n",
      "4 | dec_blocks  | ModuleList       | 2.7 M  | train\n",
      "5 | final_conv  | Conv2d           | 99     | train\n",
      "6 | activation  | Sigmoid          | 0      | train\n",
      "7 | criterion   | L1Loss           | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.5 M     Total params\n",
      "33.830    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4155bd05cd1457faf53671080a830a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Scripts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error en experimento unet_l1_low: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_l1_low</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/898iyflz' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/898iyflz</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_141519-898iyflz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n",
      "\n",
      "[10/12] Ejecutando: unet_l2_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_141521-lptqlb5o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/lptqlb5o' target=\"_blank\">unet_l2_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/lptqlb5o' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/lptqlb5o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: unet_l2_mid\n",
      "============================================================\n",
      "model:\n",
      "  in_channels: 3\n",
      "  base_channels: 32\n",
      "  depth: 4\n",
      "  latent_dim: 128\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: MSELoss\n",
      "  name: L2\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: U-Net Autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | enc_blocks  | ModuleList       | 1.2 M  | train\n",
      "1 | downsamples | ModuleList       | 348 K  | train\n",
      "2 | bottleneck  | UNetEncoderBlock | 3.5 M  | train\n",
      "3 | up_blocks   | ModuleList       | 696 K  | train\n",
      "4 | dec_blocks  | ModuleList       | 2.7 M  | train\n",
      "5 | final_conv  | Conv2d           | 99     | train\n",
      "6 | activation  | Sigmoid          | 0      | train\n",
      "7 | criterion   | MSELoss          | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.5 M     Total params\n",
      "33.830    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64ce6a54e09412c9e6309bfd47f364c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error en experimento unet_l2_mid: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_l2_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/lptqlb5o' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/lptqlb5o</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_141521-lptqlb5o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n",
      "\n",
      "[11/12] Ejecutando: unet_ssim_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_141523-1x57aile</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/1x57aile' target=\"_blank\">unet_ssim_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/1x57aile' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/1x57aile</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: unet_ssim_mid\n",
      "============================================================\n",
      "model:\n",
      "  in_channels: 3\n",
      "  base_channels: 32\n",
      "  depth: 4\n",
      "  latent_dim: 128\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM\n",
      "  name: SSIM\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: U-Net Autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | enc_blocks  | ModuleList       | 1.2 M  | train\n",
      "1 | downsamples | ModuleList       | 348 K  | train\n",
      "2 | bottleneck  | UNetEncoderBlock | 3.5 M  | train\n",
      "3 | up_blocks   | ModuleList       | 696 K  | train\n",
      "4 | dec_blocks  | ModuleList       | 2.7 M  | train\n",
      "5 | final_conv  | Conv2d           | 99     | train\n",
      "6 | activation  | Sigmoid          | 0      | train\n",
      "7 | criterion   | SSIMLoss         | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.5 M     Total params\n",
      "33.830    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80619062d8284feb8692994a50d5176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error en experimento unet_ssim_mid: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_ssim_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/1x57aile' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/1x57aile</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_141523-1x57aile\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n",
      "\n",
      "[12/12] Ejecutando: unet_ssim_l1_mid\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\IA\\TareaAutoEncoders\\wandb\\run-20251118_141526-6guizr2e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/6guizr2e' target=\"_blank\">unet_ssim_l1_mid</a></strong> to <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/6guizr2e' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/6guizr2e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Ejecutando experimento: unet_ssim_l1_mid\n",
      "============================================================\n",
      "model:\n",
      "  in_channels: 3\n",
      "  base_channels: 32\n",
      "  depth: 4\n",
      "  latent_dim: 128\n",
      "trainer:\n",
      "  max_epochs: 20\n",
      "  gpus: 1\n",
      "  precision: 32\n",
      "  deterministic: true\n",
      "  check_val_every_n_epoch: 1\n",
      "  log_every_n_steps: 10\n",
      "  enable_model_summary: true\n",
      "  gradient_clip_val: 0.0\n",
      "  enable_progress_bar: true\n",
      "logger:\n",
      "  project: ae_experiments\n",
      "  entity: null\n",
      "  log_model: false\n",
      "  offline: false\n",
      "  tags: []\n",
      "loss:\n",
      "  type: SSIM_L1\n",
      "  name: SSIM+L1\n",
      "  window_size: 11\n",
      "  sigma: 1.5\n",
      "  data_range: 1.0\n",
      "  l1_weight: 0.1\n",
      "optimizer:\n",
      "  name: adam_mid\n",
      "  type: Adam\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "seed: 42\n",
      "data:\n",
      "  data_dir: DATASET_128x128\n",
      "  image_size: 128\n",
      "  batch_size: 32\n",
      "  num_workers: 0\n",
      "  validation_split: 0.15\n",
      "  test_split: 0.15\n",
      "callbacks:\n",
      "  monitor: val/loss\n",
      "  mode: min\n",
      "  filename: '{epoch:02d}-{val/loss:.4f}'\n",
      "  save_top_k: 3\n",
      "experiment:\n",
      "  name: default_experiment\n",
      "  description: Default autoencoder experiment\n",
      "\n",
      "📌 Modelo: U-Net Autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | enc_blocks  | ModuleList       | 1.2 M  | train\n",
      "1 | downsamples | ModuleList       | 348 K  | train\n",
      "2 | bottleneck  | UNetEncoderBlock | 3.5 M  | train\n",
      "3 | up_blocks   | ModuleList       | 696 K  | train\n",
      "4 | dec_blocks  | ModuleList       | 2.7 M  | train\n",
      "5 | final_conv  | Conv2d           | 99     | train\n",
      "6 | activation  | Sigmoid          | 0      | train\n",
      "7 | criterion   | SSIML1Combined   | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.5 M     Total params\n",
      "33.830    Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d094357627a4deb826b3cd99cc272f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error en experimento unet_ssim_l1_mid: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_ssim_l1_mid</strong> at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/6guizr2e' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments/runs/6guizr2e</a><br> View project at: <a href='https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments' target=\"_blank\">https://wandb.ai/fdbrenes17-tec-costa-rica/ae_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251118_141526-6guizr2e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Given transposed=1, weight of size [256, 256, 2, 2], expected input[32, 512, 16, 16] to have 256 channels, but got 512 channels instead\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENTACIÓN COMPLETADA\n",
      "✅ Exitosos: 8\n",
      "❌ Fallidos: 4\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ImageReconstructionLogger(pl.Callback):\n",
    "    \"\"\"Callback para loguear reconstrucciones de imágenes\"\"\"\n",
    "    \n",
    "    def __init__(self, num_images=4):\n",
    "        super().__init__()\n",
    "        self.num_images = num_images\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"Loguea reconstrucciones al final de cada epoch de validación\"\"\"\n",
    "        try:\n",
    "            val_loader = trainer.datamodule.val_dataloader()\n",
    "            batch = next(iter(val_loader))\n",
    "            batch = batch[:self.num_images].to(pl_module.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                reconstructed = pl_module(batch)\n",
    "            \n",
    "            # Asegurar que están en CPU\n",
    "            batch_cpu = batch.cpu()\n",
    "            reconstructed_cpu = reconstructed.cpu()\n",
    "            \n",
    "            # Convertir a numpy - formato [B, C, H, W] -> [B, H, W, C]\n",
    "            original_imgs = batch_cpu.numpy().transpose(0, 2, 3, 1)\n",
    "            reconstructed_imgs = reconstructed_cpu.numpy().transpose(0, 2, 3, 1)\n",
    "            \n",
    "            # Crear visualización\n",
    "            images_to_log = []\n",
    "            for i in range(len(original_imgs)):\n",
    "                original = original_imgs[i]\n",
    "                recon = reconstructed_imgs[i]\n",
    "                \n",
    "                # Concatenar original y reconstruida lado a lado\n",
    "                combined = np.concatenate([original, recon], axis=1)\n",
    "                \n",
    "                # Asegurar que está en rango [0, 1]\n",
    "                combined = np.clip(combined, 0, 1)\n",
    "                \n",
    "                images_to_log.append(\n",
    "                    wandb.Image(combined, caption=f\"Original vs Reconstructed {i}\")\n",
    "                )\n",
    "            \n",
    "            if len(images_to_log) > 0:\n",
    "                wandb.log({\"reconstructions\": images_to_log}, step=trainer.global_step)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error en ImageReconstructionLogger: {e}\")\n",
    "\n",
    "\n",
    "class LatentSpaceVisualizer(pl.Callback):\n",
    "    \"\"\"Callback para visualizar el espacio latente con PCA\"\"\"\n",
    "    \n",
    "    def __init__(self, num_images=100):\n",
    "        super().__init__()\n",
    "        self.num_images = num_images\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"Visualiza el espacio latente cada N epochs\"\"\"\n",
    "        if trainer.current_epoch % 5 != 0:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from sklearn.decomposition import PCA\n",
    "            import matplotlib.pyplot as plt  # ← IMPORTAR AQUI TAMBIÉN\n",
    "        except ImportError as e:\n",
    "            print(f\"⚠️ Error de importación: {e}\")\n",
    "            return\n",
    "        \n",
    "        val_loader = trainer.datamodule.val_dataloader()\n",
    "        latent_vectors = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                if batch_idx * len(batch) >= self.num_images:\n",
    "                    break\n",
    "                \n",
    "                batch = batch.to(pl_module.device)\n",
    "                \n",
    "                try:\n",
    "                    if not hasattr(pl_module, 'encoder'):\n",
    "                        return\n",
    "                    \n",
    "                    x_enc = pl_module.encoder(batch)\n",
    "                    x_flat = pl_module.flatten(x_enc)\n",
    "                    z = pl_module.fc_mu(x_flat)\n",
    "                    latent_vectors.append(z.cpu().numpy())\n",
    "                except AttributeError as e:\n",
    "                    print(f\"⚠️ Modelo incompatible: {e}\")\n",
    "                    return\n",
    "        \n",
    "        if len(latent_vectors) == 0:\n",
    "            print(\"⚠️ No hay vectores latentes\")\n",
    "            return\n",
    "        \n",
    "        latent_vectors = np.concatenate(latent_vectors, axis=0)\n",
    "        \n",
    "        print(f\"📊 Aplicando PCA a {len(latent_vectors)} muestras...\")\n",
    "        try:\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "            latent_2d = pca.fit_transform(latent_vectors)\n",
    "            \n",
    "            fig = self._create_plot(latent_2d, pca)\n",
    "            wandb.log({\"latent_space\": wandb.Image(fig)}, step=trainer.global_step)\n",
    "            plt.close(fig)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error en PCA: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_plot(latent_2d, pca):\n",
    "        \"\"\"Crea figura con PCA\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        scatter = ax.scatter(\n",
    "            latent_2d[:, 0], \n",
    "            latent_2d[:, 1], \n",
    "            c=range(len(latent_2d)), \n",
    "            cmap='viridis', \n",
    "            alpha=0.6, \n",
    "            s=50\n",
    "        )\n",
    "        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "        ax.set_title('Latent Space Visualization (PCA)')\n",
    "        plt.colorbar(scatter, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "\n",
    "class AnomalyDetectionVisualizer(pl.Callback):\n",
    "    \"\"\"Callback para visualizar reconstrucciones de imágenes normales y anómalas\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir='DATASET_128x128', num_images=4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.num_images = num_images\n",
    "        self.test_dataset = None\n",
    "    \n",
    "    def setup(self, trainer, pl_module, stage=None):\n",
    "        \"\"\"Configurar dataset de prueba\"\"\"\n",
    "        if self.test_dataset is None:\n",
    "            self.test_dataset = MVTecDataset(\n",
    "                root_dir=self.data_dir,\n",
    "                split='test',\n",
    "                transform=transforms.ToTensor()\n",
    "            )\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"Visualiza reconstrucciones del set de prueba\"\"\"\n",
    "        if trainer.current_epoch % 5 != 0:\n",
    "            return\n",
    "        \n",
    "        if self.test_dataset is None or len(self.test_dataset) == 0:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Obtener muestras aleatorias\n",
    "            n_samples = min(self.num_images, len(self.test_dataset))\n",
    "            indices = np.random.choice(len(self.test_dataset), n_samples, replace=False)\n",
    "            test_images = []\n",
    "            \n",
    "            for idx in indices:\n",
    "                test_images.append(self.test_dataset[idx])\n",
    "            \n",
    "            test_batch = torch.stack(test_images).to(pl_module.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                reconstructed = pl_module(test_batch)\n",
    "            \n",
    "            # Calcular MSE\n",
    "            mse = torch.mean((test_batch - reconstructed) ** 2, dim=[1, 2, 3])\n",
    "            \n",
    "            # Pasar a CPU\n",
    "            test_batch_cpu = test_batch.cpu()\n",
    "            reconstructed_cpu = reconstructed.cpu()\n",
    "            \n",
    "            # Convertir a numpy\n",
    "            original_imgs = test_batch_cpu.numpy().transpose(0, 2, 3, 1)\n",
    "            reconstructed_imgs = reconstructed_cpu.numpy().transpose(0, 2, 3, 1)\n",
    "            error_maps = mse.cpu().numpy()\n",
    "            \n",
    "            # Crear visualizaciones\n",
    "            images_to_log = []\n",
    "            median_error = np.median(error_maps)\n",
    "            \n",
    "            for i in range(len(original_imgs)):\n",
    "                original = original_imgs[i]\n",
    "                recon = reconstructed_imgs[i]\n",
    "                error = error_maps[i]\n",
    "                \n",
    "                # Normalizar error map a [0, 1]\n",
    "                error_normalized = (error - error_maps.min()) / (error_maps.max() - error_maps.min() + 1e-8)\n",
    "                error_map_3ch = np.stack([error_normalized] * 3, axis=-1)\n",
    "                \n",
    "                # Concatenar paneles\n",
    "                combined = np.concatenate([original, recon, error_map_3ch], axis=1)\n",
    "                combined = np.clip(combined, 0, 1)\n",
    "                \n",
    "                label = \"Good\" if error < median_error else \"Anomaly\"\n",
    "                images_to_log.append(\n",
    "                    wandb.Image(combined, caption=f\"{label} - MSE: {error:.4f}\")\n",
    "                )\n",
    "            \n",
    "            if len(images_to_log) > 0:\n",
    "                wandb.log({\"test_reconstructions\": images_to_log}, step=trainer.global_step)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error en AnomalyDetectionVisualizer: {e}\")\n",
    "\n",
    "\n",
    "def run_experiment(config_name, model_name, loss_name, optimizer_name, run_name):\n",
    "    \"\"\"\n",
    "    Ejecuta un experimento con la configuración especificada\n",
    "    \n",
    "    Args:\n",
    "        config_name: nombre de la configuración base (default: 'config')\n",
    "        model_name: nombre del modelo en conf/model/\n",
    "        loss_name: nombre de la función de pérdida en conf/loss/\n",
    "        optimizer_name: nombre del optimizador en conf/optimizer/\n",
    "        run_name: nombre del run en WandB\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar WandB\n",
    "    wandb.init(\n",
    "        project=\"ae_experiments\",\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"model\": model_name,\n",
    "            \"loss\": loss_name,\n",
    "            \"optimizer\": optimizer_name,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Cargar configuración con Hydra\n",
    "        with initialize(config_path=\"conf\", version_base=None):\n",
    "            cfg = compose(\n",
    "                config_name=config_name,\n",
    "                overrides=[\n",
    "                    f\"model={model_name}\",\n",
    "                    f\"loss={loss_name}\",\n",
    "                    f\"optimizer={optimizer_name}\",\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Ejecutando experimento: {run_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(OmegaConf.to_yaml(cfg))\n",
    "        \n",
    "        # Crear DataModule\n",
    "        dm = MVTecDataModule(\n",
    "            data_dir=cfg.data.data_dir,\n",
    "            batch_size=cfg.data.batch_size,\n",
    "            num_workers=cfg.data.num_workers,\n",
    "            val_split=cfg.data.validation_split,\n",
    "        )\n",
    "        \n",
    "        # Instanciar modelo\n",
    "        model_type = model_name.lower()\n",
    "        if \"unet\" in model_type:\n",
    "            print(\"📌 Modelo: U-Net Autoencoder\")\n",
    "            model = LitUNetAutoencoder(\n",
    "                model_cfg=cfg.model,\n",
    "                loss_cfg=cfg.loss,\n",
    "                optimizer_cfg=cfg.optimizer,\n",
    "            )\n",
    "        else:\n",
    "            print(\"📌 Modelo: Autoencoder Clásico\")\n",
    "            model = LitAutoencoder(\n",
    "                model_cfg=cfg.model,\n",
    "                loss_cfg=cfg.loss,\n",
    "                optimizer_cfg=cfg.optimizer,\n",
    "                image_size=cfg.data.image_size,\n",
    "            )\n",
    "        \n",
    "        # Callbacks personalizados\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_top_k=3,\n",
    "                save_last=True,\n",
    "                dirpath=f\"checkpoints/{run_name}\",\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                patience=10,\n",
    "                verbose=True,\n",
    "            ),\n",
    "            ImageReconstructionLogger(num_images=4),\n",
    "            LatentSpaceVisualizer(num_images=100),\n",
    "            AnomalyDetectionVisualizer(num_images=4),\n",
    "        ]\n",
    "        \n",
    "        # Logger de WandB\n",
    "        wandb_logger = WandbLogger(\n",
    "            project=\"ae_experiments\",\n",
    "            name=run_name,\n",
    "            log_model=True,\n",
    "        )\n",
    "        \n",
    "        # Trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=cfg.trainer.max_epochs,\n",
    "            logger=wandb_logger,\n",
    "            callbacks=callbacks,\n",
    "            log_every_n_steps=cfg.trainer.log_every_n_steps,\n",
    "            deterministic=cfg.trainer.deterministic,\n",
    "            enable_model_summary=cfg.trainer.enable_model_summary,\n",
    "            enable_progress_bar=cfg.trainer.enable_progress_bar,\n",
    "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "            devices=1,\n",
    "        )\n",
    "        \n",
    "        # Entrenar\n",
    "        print(f\"\\n🚀 Iniciando entrenamiento...\")\n",
    "        trainer.fit(model, datamodule=dm)\n",
    "        \n",
    "        # Evaluar en test set\n",
    "        print(f\"\\n📊 Evaluando en test set...\")\n",
    "        trainer.test(model, datamodule=dm)\n",
    "        \n",
    "        # Loguear métricas finales\n",
    "        wandb.log({\n",
    "            \"final_train_loss\": trainer.callback_metrics.get('train_loss', 0),\n",
    "            \"final_val_loss\": trainer.callback_metrics.get('val_loss', 0),\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n✅ Experimento completado: {run_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en experimento {run_name}: {str(e)}\")\n",
    "        wandb.finish(exit_code=1)\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "def run_all_experiments():\n",
    "    \"\"\"Ejecuta todos los experimentos configurados\"\"\"\n",
    "    \n",
    "    # Configuración de experimentos\n",
    "    # Formato: (modelo, pérdida, optimizador)\n",
    "    experiments = [\n",
    "        # Autoencoder clásico con diferentes pérdidas\n",
    "        (\"autoencoder_small\", \"l1\", \"adam_low\", \"ae_small_l1_low\"),\n",
    "        (\"autoencoder_small\", \"l2\", \"adam_mid\", \"ae_small_l2_mid\"),\n",
    "        (\"autoencoder_small\", \"ssim\", \"adam_mid\", \"ae_small_ssim_mid\"),\n",
    "        (\"autoencoder_small\", \"ssim_l1\", \"adam_mid\", \"ae_small_ssim_l1_mid\"),\n",
    "        \n",
    "        # Autoencoder clásico con latent_dim grande\n",
    "        (\"autoencoder_large\", \"l1\", \"adam_low\", \"ae_large_l1_low\"),\n",
    "        (\"autoencoder_large\", \"l2\", \"adam_mid\", \"ae_large_l2_mid\"),\n",
    "        (\"autoencoder_large\", \"ssim\", \"adam_mid\", \"ae_large_ssim_mid\"),\n",
    "        (\"autoencoder_large\", \"ssim_l1\", \"adam_mid\", \"ae_large_ssim_l1_mid\"),\n",
    "        \n",
    "        # U-Net con diferentes pérdidas\n",
    "        (\"unet\", \"l1\", \"adam_low\", \"unet_l1_low\"),\n",
    "        (\"unet\", \"l2\", \"adam_mid\", \"unet_l2_mid\"),\n",
    "        (\"unet\", \"ssim\", \"adam_mid\", \"unet_ssim_mid\"),\n",
    "        (\"unet\", \"ssim_l1\", \"adam_mid\", \"unet_ssim_l1_mid\"),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"INICIANDO EXPERIMENTACIÓN CON {len(experiments)} CONFIGURACIONES\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, (model, loss, optimizer, run_name) in enumerate(experiments, 1):\n",
    "        print(f\"\\n[{i}/{len(experiments)}] Ejecutando: {run_name}\")\n",
    "        \n",
    "        try:\n",
    "            run_experiment(\n",
    "                config_name=\"config\",\n",
    "                model_name=model,\n",
    "                loss_name=loss,\n",
    "                optimizer_name=optimizer,\n",
    "                run_name=run_name,\n",
    "            )\n",
    "            successful += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EXPERIMENTACIÓN COMPLETADA\")\n",
    "    print(f\"✅ Exitosos: {successful}\")\n",
    "    print(f\"❌ Fallidos: {failed}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear directorio para checkpoints\n",
    "    Path(\"checkpoints\").mkdir(exist_ok=True)\n",
    "    \n",
    "    # Ejecutar todos los experimentos\n",
    "    run_all_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
