{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c802f3",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2ec7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfac406",
   "metadata": {},
   "source": [
    "### Se toman las 4 carpetas (cable, capsule, screw y transistor) y se separa su información de testing training y se juntan en un solo dataset, igualmente guardando las etiquetas y se setea el tamaño de cada imagen en 128x128 como se indica en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "DATASETS = ['cable', 'capsule', 'screw', 'transistor']\n",
    "BASE_PATH = Path('../TareaAutoEncoders')\n",
    "OUTPUT_PATH = BASE_PATH / 'DATASET_128x128'\n",
    "IMAGE_SIZE = (128, 128)\n",
    "\n",
    "# Crear estructura de salida (carpetas planas)\n",
    "for split in ['train', 'test', 'ground_truth']:\n",
    "    (OUTPUT_PATH / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def process_and_save(src_path: Path, dest_dir: Path, prefix: str, is_mask=False):\n",
    "    \"\"\"Lee, redimensiona y guarda. Si is_mask usa INTER_NEAREST.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(src_path), cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ No se pudo leer: {src_path}\")\n",
    "            return False\n",
    "        interp = cv2.INTER_NEAREST if is_mask else cv2.INTER_AREA\n",
    "        resized = cv2.resize(img, IMAGE_SIZE, interpolation=interp)\n",
    "        dest = dest_dir / f\"{prefix}_{src_path.stem}{src_path.suffix}\"\n",
    "        cv2.imwrite(str(dest), resized)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error con {src_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Procesar datasets\n",
    "for dataset in DATASETS:\n",
    "    base = BASE_PATH / dataset\n",
    "\n",
    "    # train -> normalmente sólo 'good' en estos datasets\n",
    "    train_dir = base / 'train'\n",
    "    if train_dir.exists():\n",
    "        for cls in train_dir.iterdir():\n",
    "            if not cls.is_dir(): \n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_train_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'train', prefix, is_mask=False)\n",
    "\n",
    "    # test -> incluir good y defectos\n",
    "    test_dir = base / 'test'\n",
    "    if test_dir.exists():\n",
    "        for cls in test_dir.iterdir():\n",
    "            if not cls.is_dir():\n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_test_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'test', prefix, is_mask=False)\n",
    "\n",
    "    # ground_truth -> máscaras (usar nearest)\n",
    "    gt_dir = base / 'ground_truth'\n",
    "    if gt_dir.exists():\n",
    "        for cls in gt_dir.iterdir():\n",
    "            if not cls.is_dir():\n",
    "                continue\n",
    "            for img in cls.glob('*.*'):\n",
    "                prefix = f\"{dataset}_gt_{cls.name}\"\n",
    "                process_and_save(img, OUTPUT_PATH / 'ground_truth', prefix, is_mask=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb3c98",
   "metadata": {},
   "source": [
    "## Configuración de los archivos Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123bc177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio conf/ creado\n"
     ]
    }
   ],
   "source": [
    "# Crear estructura base\n",
    "conf_path = Path(\"conf\")\n",
    "conf_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Directorio conf/ creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209cb794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Subdirectorios creados:\n",
      "   - conf/model/\n",
      "   - conf/trainer/\n",
      "   - conf/logger/\n",
      "   - conf/loss/\n",
      "   - conf/optimizer/\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: Crear carpetas necesarias\n",
    "subdirs = [\"model\", \"trainer\", \"logger\", \"loss\", \"optimizer\"]\n",
    "for subdir in subdirs:\n",
    "    (conf_path / subdir).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✅ Subdirectorios creados:\")\n",
    "for subdir in subdirs:\n",
    "    print(f\"   - conf/{subdir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91ae3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variaciones de modelo creadas:\n",
      "   - autoencoder_latent_small (128)\n",
      "   - autoencoder_latent_large (1024)\n"
     ]
    }
   ],
   "source": [
    "# Celda: Crear variaciones de configuración para experimentos\n",
    "# Variación 1: Latent dim pequeño\n",
    "latent_small_yaml = \"\"\"name: autoencoder_latent_small\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 128\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_latent_small.yaml\", \"w\") as f:\n",
    "    f.write(latent_small_yaml)\n",
    "\n",
    "# Variación 2: Latent dim grande\n",
    "latent_large_yaml = \"\"\"name: autoencoder_latent_large\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 1024\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_latent_large.yaml\", \"w\") as f:\n",
    "    f.write(latent_large_yaml)\n",
    "\n",
    "print(\"Variaciones de modelo creadas:\")\n",
    "print(\"   - autoencoder_latent_small (128)\")\n",
    "print(\"   - autoencoder_latent_large (1024)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53282c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/config.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 3: Crear conf/config.yaml (configuración principal)\n",
    "config_yaml = \"\"\"defaults:\n",
    "  - model: autoencoder\n",
    "  - trainer: default\n",
    "  - logger: wandb\n",
    "  - loss: l2\n",
    "  - optimizer: adam_mid\n",
    "\n",
    "seed: 42\n",
    "\n",
    "data:\n",
    "  data_dir: 'DATASET_128x128'\n",
    "  image_size: 128\n",
    "  batch_size: 32\n",
    "  num_workers: 2\n",
    "  validation_split: 0.15\n",
    "  test_split: 0.15\n",
    "\n",
    "callbacks:\n",
    "  monitor: \"val/loss\"\n",
    "  mode: \"min\"\n",
    "  filename: \"{epoch:02d}-{val/loss:.4f}\"\n",
    "  save_top_k: 3\n",
    "\n",
    "experiment:\n",
    "  name: \"default_experiment\"\n",
    "  description: \"Default autoencoder experiment\"\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/config.yaml\", \"w\") as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(\"conf/config.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e13d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 4: Crear modelos - conf/model/autoencoder.yaml\n",
    "autoencoder_yaml = \"\"\"name: autoencoder\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256]\n",
    "latent_dim: 512\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb5d4d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/unet.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: Crear modelos - conf/model/unet.yaml\n",
    "unet_yaml = \"\"\"name: unet\n",
    "in_channels: 3\n",
    "base_channels: 32\n",
    "depth: 4\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/unet.yaml\", \"w\") as f:\n",
    "    f.write(unet_yaml)\n",
    "\n",
    "print(\"conf/model/unet.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c4fef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder_small.yaml creado (latent_dim: 128)\n"
     ]
    }
   ],
   "source": [
    "# Celda 6: Variaciones de autoencoder con latent_dim pequeño\n",
    "autoencoder_small_yaml = \"\"\"name: autoencoder_small\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128]\n",
    "latent_dim: 128\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_small.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_small_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder_small.yaml creado (latent_dim: 128)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b03c99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/model/autoencoder_large.yaml creado (latent_dim: 1024)\n"
     ]
    }
   ],
   "source": [
    "# Celda 7: Variaciones de autoencoder con latent_dim grande\n",
    "autoencoder_large_yaml = \"\"\"name: autoencoder_large\n",
    "in_channels: 3\n",
    "hidden_dims: [32, 64, 128, 256, 512]\n",
    "latent_dim: 1024\n",
    "use_batch_norm: true\n",
    "dropout_rate: 0.1\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/model/autoencoder_large.yaml\", \"w\") as f:\n",
    "    f.write(autoencoder_large_yaml)\n",
    "\n",
    "print(\"conf/model/autoencoder_large.yaml creado (latent_dim: 1024)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3cdcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/l1.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 8: Funciones de pérdida - L1\n",
    "l1_yaml = \"\"\"name: l1\n",
    "type: L1Loss\n",
    "weight: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/l1.yaml\", \"w\") as f:\n",
    "    f.write(l1_yaml)\n",
    "\n",
    "print(\"conf/loss/l1.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae19c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/l2.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 9: Funciones de pérdida - L2 (MSE)\n",
    "l2_yaml = \"\"\"name: l2\n",
    "type: MSELoss\n",
    "weight: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/l2.yaml\", \"w\") as f:\n",
    "    f.write(l2_yaml)\n",
    "\n",
    "print(\"conf/loss/l2.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "818cd767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/ssim.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 10: Funciones de pérdida - SSIM\n",
    "ssim_yaml = \"\"\"name: ssim\n",
    "type: SSIMLoss\n",
    "weight: 1.0\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/ssim.yaml\", \"w\") as f:\n",
    "    f.write(ssim_yaml)\n",
    "\n",
    "print(\"conf/loss/ssim.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e24c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/loss/ssim_l1.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 11: Funciones de pérdida - SSIM + L1\n",
    "ssim_l1_yaml = \"\"\"name: ssim_l1\n",
    "type: SSIMLoss_L1\n",
    "weight_ssim: 0.5\n",
    "weight_l1: 0.5\n",
    "window_size: 11\n",
    "sigma: 1.5\n",
    "data_range: 1.0\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/loss/ssim_l1.yaml\", \"w\") as f:\n",
    "    f.write(ssim_l1_yaml)\n",
    "\n",
    "print(\"conf/loss/ssim_l1.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f27b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/trainer/default.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 12: Trainer - conf/trainer/default.yaml\n",
    "trainer_yaml = \"\"\"max_epochs: 20\n",
    "gpus: 1\n",
    "precision: 32\n",
    "deterministic: true\n",
    "check_val_every_n_epoch: 1\n",
    "log_every_n_steps: 10\n",
    "enable_model_summary: true\n",
    "gradient_clip_val: 0.0\n",
    "enable_progress_bar: true\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/trainer/default.yaml\", \"w\") as f:\n",
    "    f.write(trainer_yaml)\n",
    "\n",
    "print(\"conf/trainer/default.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24ea0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/logger/wandb.yaml creado\n"
     ]
    }
   ],
   "source": [
    "# Celda 13: Logger - conf/logger/wandb.yaml\n",
    "wandb_yaml = \"\"\"project: ae_experiments\n",
    "entity: null\n",
    "log_model: false\n",
    "offline: false\n",
    "tags: []\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/logger/wandb.yaml\", \"w\") as f:\n",
    "    f.write(wandb_yaml)\n",
    "\n",
    "print(\"conf/logger/wandb.yaml creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01369ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_low.yaml creado (lr: 1e-4)\n"
     ]
    }
   ],
   "source": [
    "# Celda 14: Optimizer - Adam con LR bajo\n",
    "adam_low_yaml = \"\"\"name: adam_low\n",
    "type: Adam\n",
    "lr: 1e-4\n",
    "weight_decay: 0.0\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_low.yaml\", \"w\") as f:\n",
    "    f.write(adam_low_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_low.yaml creado (lr: 1e-4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eafba72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_mid.yaml creado (lr: 1e-3)\n"
     ]
    }
   ],
   "source": [
    "# Celda 15: Optimizer - Adam con LR medio\n",
    "adam_mid_yaml = \"\"\"name: adam_mid\n",
    "type: Adam\n",
    "lr: 1e-3\n",
    "weight_decay: 0.0\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_mid.yaml\", \"w\") as f:\n",
    "    f.write(adam_mid_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_mid.yaml creado (lr: 1e-3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07f83b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf/optimizer/adam_high.yaml creado (lr: 5e-3)\n"
     ]
    }
   ],
   "source": [
    "# Celda 16: Optimizer - Adam con LR alto\n",
    "adam_high_yaml = \"\"\"name: adam_high\n",
    "type: Adam\n",
    "lr: 5e-3\n",
    "weight_decay: 1e-5\n",
    "betas: [0.9, 0.999]\n",
    "\"\"\"\n",
    "\n",
    "with open(\"conf/optimizer/adam_high.yaml\", \"w\") as f:\n",
    "    f.write(adam_high_yaml)\n",
    "\n",
    "print(\"conf/optimizer/adam_high.yaml creado (lr: 5e-3)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
